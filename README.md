# Angel Eye 设计理念：为 AI 装上“知识僚机”

## 1. 我们遇到了什么问题？—— AI 的“记忆鸿沟”

想象一下，你正在和一个无所不知的朋友聊天。他学识渊博，能和你从诗词歌赋聊到人生哲学。但当你提到上周刚上映的电影，或是你圈子里最新的热梗时，他却一脸茫然。

这就是当前大语言模型（LLM）普遍面临的困境——**“记忆鸿沟”**。

尽管它们拥有海量的通用知识，但这些知识是“过去式”的。它们不认识新出的游戏角色，不了解最新的网络流行语，更不懂你公司内部的项目代号。这种知识的滞后性，使得它们在面对需要实时性、领域性知识的对话时，往往会显得格格不入，甚至给出错误的、过时的信息。

我们创造 `Angel Eye`，就是为了填补这条鸿沟。

## 2. 我们的构想是什么？—— 一个“知识僚机”，而非另一个“大脑”

`Angel Eye` 的核心思想极其简单：**它不是要取代大模型，而是要成为它最得力的“信息僚机” (Information Wingman)。**

我们不打算再造一个无所不包的“大脑”，而是要打造一个轻量、敏锐、高效的“知识外挂”。当主模型在对话中遇到它不认识的“专有名词”时，`Angel Eye` 会在幕后悄无声息地完成三件事：

1.  **察言观色 (Context Sensing)**: 它会迅速浏览上下文，像一个真正的聊天伙伴一样，根据语境（比如“大家都在聊原神”）来推断这个陌生名词（比如“芙宁娜”）可能属于哪个领域。
2.  **精准补给 (Targeted Retrieval)**: 它会立刻从最合适的知识库（比如“萌娘百科”而非“维基百科”）中，调取关于这个名词的最新、最准确的信息。
3.  **过滤与重组 (Filter & Reorganize)**: 它会审阅获取到的全部信息，**过滤掉无关内容（如网站模板、广告、不相关的章节），然后将所有与角色身份、故事、能力等高度相关的信息，重组成一份结构化的背景材料**，像一张详细的备忘录一样，悄悄递给主模型。

整个过程对用户完全透明。用户感受到的，只是和他们对话的 AI 突然变得“见多识广”，总能跟上最新的话题，总能理解最刁钻的黑话。

## 3. 它将带来怎样的改变？—— 从“尬聊”到“共鸣”

**没有 Angel Eye 的世界:**

> **你:** “我觉得芙宁娜的角色塑造比甘雨要复杂多了，她那种双重身份的挣扎感太强了。”
> **AI (知识库里只有甘雨):** “甘雨是《原神》中一位尽职尽责的秘书，拥有麒麟血脉。关于‘芙宁娜’，我暂时没有相关信息。我们可以多聊聊关于甘雨的话题吗？”
> *(对话跑偏，无法深入)*

**拥有 Angel Eye 的世界:**

> **你:** “我觉得芙宁娜的角色塑造比甘雨要复杂多了，她那种双重身份的挣扎感太强了。”
> **AI (瞬间接收到僚机递来的“芙宁娜”背景材料):** “完全同意。甘雨的内心挣扎更多源于半人半仙的身份认同与孤独感，而芙宁娜则是在‘神’与‘人’的双重身份下，背负了整个枫丹的命运长达五百年。她表面上的浮夸与内心的坚韧、痛苦形成的巨大反差，确实让这个角色的弧光更加动人。”
> *(对话深入，产生强烈共鸣)*

`Angel Eye` 的价值，就是将前一种“尬聊”场景，无缝地转化为后一种“共鸣”场景。它让 AI 不再是一个被动的信息检索工具，而是一个能够主动学习、实时同步知识的、真正意义上的“对话伙伴”。

## 4. 我们的设计原则

为了实现这个愿景，我们遵循三大设计原则：

*   **无缝 (Seamless)**: 它的存在对用户和主模型都应该是无感的。它像一个后台服务一样静默运行，只在必要时介入，绝不干扰主对话流程。
*   **高效 (Efficient)**: 整个预处理流程（分析、检索、过滤）都由轻量、快速、低成本的模型或服务完成，确保在不显著增加延迟的前提下，最大化地提升对话质量。
*   **开放 (Open)**: 它的知识库是可插拔、可扩展的。今天我们可以接入萌娘百科，明天就可以轻松地为它增加公司的内部文档、特定游戏的数据库，或是任何我们需要的知识源。

最终，`Angel Eye` 的目标，是让每一个与我们 AI 交互的用户，都能享受到一种信息同步、知识对齐的、真正智能的对话体验。